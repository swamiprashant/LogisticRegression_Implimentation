# -*- coding: utf-8 -*-
"""Logistic_Regression_implimentation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GYwlgw9rrTHOZKaj8o9OoobX8r2K9NNO
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.datasets import load_diabetes

diabetes = load_diabetes()

diabetes

print(diabetes.DESCR)

from sklearn.datasets import load_iris

iris = load_iris()

iris

iris.keys()

print(iris.DESCR)

iris.data

iris.target

iris.feature_names

data = pd.DataFrame(iris.data, columns = iris.feature_names)

data

data["target"] = iris.target

data

data.sample(2)

data.target.unique()

# for bunary classification.
df = data[data['target']!=2]

df.target.unique()

x = df.iloc[:,:-1]
y = df.iloc[:, -1]

x

y

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)

X_train

X_test

X_train.shape, X_test.shape, y_train.shape, y_test.shape

from sklearn.linear_model import LogisticRegression

model = LogisticRegression()

model

model.fit(X_train, y_train)

y_pred_prog = model.predict(X_test)

y_pred_prog

model.coef_

model.intercept_

y_pred_prob= model.predict_proba(X_test)[:, 1]

y_pred_prob

# evaluation matrics
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report

confusion_matrix = confusion_matrix(y_test, y_pred_prog)

confusion_matrix

accuracy_score = accuracy_score(y_test, y_pred_prog)

accuracy_score

print(classification_report(y_test, y_pred_prog))

from sklearn.metrics import roc_curve, auc

fpr, tpr, threshioles = roc_curve(y_test, y_pred_prob)

fpr

tpr

#calcilate area under curve
roc_auc = auc(fpr, tpr)
roc_auc

plt.figure(figsize=(5, 8))
plt.plot(fpr, tpr, color = 'darkorange', linewidth = 2, label = 'ROC_CURVE')
plt.plot([0, 1], [0, 1], color= 'navy', linewidth=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False positive rate')
plt.ylabel('Tru positive rate')
plt.title('Recive operating curve Roc curve')
plt.legend(loc="lower right")
plt.show()

# cross validation
from sklearn.linear_model import LogisticRegressionCV

model = LogisticRegressionCV()

model



from sklearn.model_selection import KFold

cv = KFold(n_splits = 5)
cv

from sklearn.model_selection import cross_val_score

mean1 = cross_val_score(model, X_train, y_train, cv = cv, scoring = "accuracy")

np.mean(mean1)

from sklearn.datasets import make_classification
from sklearn.linear_model import LogisticRegressionCV
x, y = make_classification(n_samples = 1000, n_features = 10, n_redundant = 5, n_informative = 5, n_classes = 2, random_state = 1)

x

y

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.30, random_state = 1)

X_train

model = LogisticRegression()

model

model.fit(X_train, y_train)

y_pred = model.predict(X_test)
y_pred

from sklearn.metrics import confusion_matrix, accuracy_score, classification_report

confusion_matrix = confusion_matrix(y_test, y_pred)
accuracy_score = accuracy_score(y_test, y_pred)
classification_report = classification_report(y_test, y_pred)

confusion_matrix

accuracy_score

print(classification_report)

from sklearn.metrics import roc_curve, auc

y_proba = model.predict_proba(X_test)[:, 1]

fpr, tpr, threshold = roc_curve(y_test, y_proba)

fpr

tpr

threshold

plt.figure(figsize=(5, 8))
plt.plot(fpr, tpr, color = 'darkorange', linewidth=2, label='roc_curve')
plt.plot([0, 1], [1, 0], color = 'navy', linewidth=2, linestyle='--')
plt.xlim([0, 1], [0, 1])
plt.ylim([0, 1], [0, 1.05])
plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('recive operating')
plt.legend(loc='lower light')
plt.show()

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.30, random_state=1)

X_train

X_test

from sklearn.linear_model import LinearRegression

model

model.fit(X_train, y_train)

model.coef_

model.intercept_

y_preb = model.predict(X_train)[:, 1]

from sklearn.datasets import make_classification
from sklearn.linear_model import LogisticRegression
x, y = make_classification(n_samples = 1000, n_redundant = 5, n_features = 10, n_informative=5, n_classes=2, random_state = 1 )

x

y

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.30, random_state = 1)

X_train

X_test

# hyperparameter
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LogisticRegression

params = ({'penalty':('l1', 'l2', 'elasticNet'), 'C':[1, 2, 10, 12, 23]})

classifier  = LogisticRegression()
classifier

clf = GridSearchCV(classifier, param_grid = params, scoring = 'accuracy', cv = 5)
clf

import warnings
warnings.filterwarnings("ignore")
clf.fit(X_train, y_train)

clf.best_params_

clf.best_score_

model = LogisticRegression(C = 1, penalty = 'l2')

model

model.fit(X_train, y_train)

y_pred = model.predict(X_test)
y_pred

y_pred_prob = model.predict_proba(X_test)

y_pred_prob

from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
print(confusion_matrix(y_test, y_pred))
print(accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))

# randomization search cv, it will take randomaly some combination
from sklearn.model_selection import RandomizedSearchCV
randomized_clf = RandomizedSearchCV(classifier, param_distributions = params, cv = 5, n_iter=10)
randomized_clf

randomized_clf.fit(X_train, y_train)

randomized_clf.best_params_

randomized_clf.best_score_

model = LogisticRegression(C = 23, penalty = 'l2')
model

model.fit(X_train, y_train)

y_pred = model.predict(X_test)

y_pred

from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
print(confusion_matrix(y_test, y_pred))
print(accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))

